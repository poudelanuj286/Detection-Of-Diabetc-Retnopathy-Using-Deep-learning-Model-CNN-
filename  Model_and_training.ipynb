{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" here all the necessay modules and packages \"\"\"\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import check_output\n",
    "\n",
    "\n",
    "# from keras.models import Sequential,Model\n",
    "# from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Input,Dropout,Activation,BatchNormalization\n",
    "# from keras import losses\n",
    "# from keras.optimizers import Adam, Adagrad\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras import regularizers\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# import keras\n",
    "# from keras.layers import LeakyReLU, PReLU\n",
    "# import os\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.python.keras.models import Sequential,Model\n",
    "from tensorflow.python.keras.layers import Conv2D,MaxPooling2D,Input,Dense,Flatten,Dropout,Activation,BatchNormalization,GlobalAveragePooling2D\n",
    "from tensorflow.python.keras.layers import PReLU\n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras.optimizers import Adam, Adagrad\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras import regularizers\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from tensorflow.python.keras.layers import LeakyReLU, PReLU\n",
    "import os\n",
    "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
    "# from tensorflow.python.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.python.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.python.keras.applications.inception_v3 import InceptionV3\n",
    "from tqdm import tqdm\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''here now actuall process stats\n",
    "first we used a keras image data generator'''\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "#     zoom_range=[0.5, 1.25],\n",
    "#     rotation_range=30,\n",
    "#     width_shift_range=0.1,\\\n",
    "#     height_shift_range=0.1,\n",
    "#     horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    data_format='channels_last',\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    validation_split =0.2 \n",
    ")\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "#     horizontal_flip=True,\n",
    "#                                   zoom_range=[0.5, 1.25],\n",
    "    rescale=1./255, \n",
    "#     preprocessing_function=custom_func\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' here i have used a flow_from_directory method from keras which requires \n",
    "    a folders with respective classes and images and reads that folders and automatically identifies the class.'''\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/content/train',\n",
    "    target_size=(512,512),\n",
    "    batch_size=32,\n",
    "    color_mode = 'rgb',\n",
    "    shuffle = True,\n",
    "    seed = 42,\n",
    "    class_mode='categorical',#class_mode can be binary for binary classification\n",
    "    subset = 'training')\n",
    "\n",
    "\n",
    "\n",
    "valid_generator = train_datagen.flow_from_directory(\n",
    "    directory=\"/content/train\",\n",
    "    target_size=(512, 512),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset ='validation'\n",
    "    )\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=\"/content/remake\",\n",
    "    target_size=(512, 512),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=16,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer learning\n",
    "base_model = ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createmodel():\n",
    "  model = Sequential()\n",
    "  model.add(base_model) #loads above imported pretrained model\n",
    "  \n",
    "''' this is the custom model. You can use this too'''\n",
    "    \n",
    "  # model.add(Conv2D(32,kernel_size = (7,7),strides=2, input_shape=(512,512,3), padding='same',activation=PReLU(),name='convolution1'))\n",
    "  # model.add(BatchNormalization(),name='BN')\n",
    "  # model.add(MaxPooling2D(pool_size=(2, 2),strides=2,name='max_pooling1'))\n",
    "  \n",
    "  \n",
    "  # model.add(Conv2D(32,kernel_size = (2,2),strides=1,padding='same', activation=PReLU(),name='convolution2'))  \n",
    "  # model.add(BatchNormalization())\n",
    "  \n",
    "  # model.add(Conv2D(32,kernel_size = (2,2),strides=1,padding='same', activation=PReLU(),name='convolution3'))  \n",
    "  # model.add(BatchNormalization())\n",
    "  # model.add(MaxPooling2D(pool_size=(2, 2),strides=2, padding='valid'))\n",
    "\n",
    "  # model.add(Conv2D(32,kernel_size = (2,2),strides=1,padding='same', activation=PReLU()),name='convolution4')  \n",
    "  # model.add(BatchNormalization())\n",
    "  # model.add(Conv2D(32,kernel_size = (2,2),strides=1,padding='same', activation=PReLU()),name='convolution5')  \n",
    "  # model.add(BatchNormalization())\n",
    "  # model.add(MaxPooling2D(pool_size=(2, 2),strides=2, padding='valid'))\n",
    "\n",
    "  \n",
    "  # model.add(Conv2D(128,kernel_size = (3,3),strides=1,padding='same', activation=PReLU()),name='convolution6')\n",
    "  # model.add(BatchNormalization())  \n",
    "  # model.add(Conv2D(128,kernel_size = (3,3),strides=1,padding='same', activation=PReLU(),name='convolution7'))\n",
    "  # model.add(BatchNormalization())\n",
    "  # model.add(Conv2D(128,kernel_size = (3,3),strides=1,padding='same', activation=PReLU(),name='convolution8'))\n",
    "  # model.add(BatchNormalization())\n",
    "  # model.add(Conv2D(128,kernel_size = (3,3),strides=1,padding='same', activation=PReLU(),name='convolution9'))\n",
    "  # model.add(BatchNormalization())\n",
    "  \n",
    "  \n",
    "  # model.add(MaxPooling2D(pool_size=(2, 2),strides=2, padding='valid'))\n",
    "  \n",
    "  \n",
    "  \n",
    "  # model.add(Conv2D(256,kernel_size = (3,3),strides=1,padding='same', activation=PReLU()))\n",
    "  # model.add(BatchNormalization())\n",
    "  # model.add(Conv2D(256,kernel_size = (3,3),strides=1,padding='same', activation=PReLU()))\n",
    "  # model.add(BatchNormalization())\n",
    "  # model.add(Conv2D(256,kernel_size = (3,3),strides=1,padding='same', activation=PReLU()))\n",
    "  # model.add(BatchNormalization())\n",
    "  # model.add(Conv2D(256,kernel_size = (3,3),strides=1,padding='same', activation=PReLU()))\n",
    "  # model.add(BatchNormalization())\n",
    "  \n",
    "  \n",
    "  # model.add(MaxPooling2D(pool_size=(2, 2),strides=2, padding='valid'))\n",
    "  # model.add(Dropout(0.5))\n",
    "  \n",
    "  # model.add(Flatten())\n",
    "  \n",
    "  \n",
    "  # model.add(Dense(1024, activation=PReLU()))\n",
    "  # model.add(Dropout(0.5))\n",
    "  \n",
    "  # model.add(Dense(512, activation=PReLU()))\n",
    "  # model.add(Dropout(0.1))\n",
    "  \n",
    "  \n",
    "  # model.add(Dense(5,activation = 'softmax'))\n",
    "  # model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "  \n",
    "  \n",
    "  \n",
    "#     #  here we added new layersD\n",
    "  model.add(GlobalAveragePooling2D())\n",
    "  model.add(Dense(1024, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(3, activation='softmax', name ='output'))\n",
    "  \n",
    "  opt = Adam(lr= 1e-3, decay= 1e-3 /100)\n",
    "  model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "  # model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "  model.summary()\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=createmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''actual training starts here'''\n",
    "\n",
    "history=model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=136,\n",
    "    epochs=50,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=33,\n",
    "    verbose=1, \n",
    "    initial_epoch=init_epoch\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib\n",
    "print(\"Generating plots...\")\n",
    "sys.stdout.flush()\n",
    "matplotlib.use(\"Agg\")\n",
    "matplotlib.pyplot.style.use(\"ggplot\")\n",
    "matplotlib.pyplot.figure()\n",
    "N =210\n",
    "matplotlib.pyplot.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "matplotlib.pyplot.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "matplotlib.pyplot.plot(np.arange(0, N), history.history[\"acc\"], label=\"train_acc\")\n",
    "matplotlib.pyplot.plot(np.arange(0, N), history.history[\"val_acc\"], label=\"val_acc\")\n",
    "matplotlib.pyplot.title(\"Training Loss and Accuracy on diabetic retinopathy detection\")\n",
    "matplotlib.pyplot.xlabel(\"Epoch #\")\n",
    "matplotlib.pyplot.ylabel(\"Loss/Accuracy\")\n",
    "matplotlib.pyplot.legend(loc=\"lower left\")\n",
    "matplotlib.pyplot.savefig(\"plot.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
